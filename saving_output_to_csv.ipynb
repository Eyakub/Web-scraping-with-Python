{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://boston.craigslist.org/search/sof\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n\n\nTotal Jobs:  17\n"
    }
   ],
   "source": [
    "npo_jobs = {}\n",
    "job_no = 0\n",
    "while True:\n",
    "    response = requests.get(url)\n",
    "    data = response.text\n",
    "    soup = BeautifulSoup(data, 'html.parser')\n",
    "    jobs = soup.find_all('p', {'class': 'result-info'})\n",
    "    \n",
    "    for job in jobs:\n",
    "        title = job.find('a', {'class': 'result-title'}).text\n",
    "        location_tag = job.find('span', {'class': 'result-hood'})\n",
    "        location = location_tag.text[2:-1] if location_tag else 'N/A'\n",
    "        date = job.find('time', {'class': 'result-date'}).text\n",
    "        link = job.find('a', {'class': 'result-title'}).get('href')\n",
    "\n",
    "        # parse the job description link\n",
    "        job_response = requests.get(link)\n",
    "        job_data = job_response.text\n",
    "        job_soup = BeautifulSoup(job_data, 'html.parser')\n",
    "        job_description = job_soup.find('section', {'id': 'postingbody'}).text\n",
    "        job_attributes_tag = job_soup.find('p', {'class': 'attrgroup'})\n",
    "        job_attributes = job_attributes_tag.text if job_attributes_tag else 'N/A'\n",
    "        \n",
    "        job_no += 1\n",
    "        npo_jobs[job_no] = [title, location, date, link, job_attributes, job_description]\n",
    "        # print('Job Title: ', title, '\\nLocation: ', location, '\\nDate: ', date, '\\nLink: ', link, '\\n', job_attributes, '\\nJob Description: ', job_description, '\\n---')\n",
    "    url_tag = soup.find('a', {'title': 'next page'})\n",
    "    if url_tag.get('href'):\n",
    "        url = 'https://boston.craigslist.org' + url_tag.get('href')\n",
    "        print(url)\n",
    "    else:\n",
    "        break\n",
    "print('\\n\\n\\nTotal Jobs: ', job_no)\n",
    "npo_jobs_df = pd.DataFrame.from_dict(npo_jobs, orient = 'index', columns = ['Job Title', 'Location', 'Date', 'Link', 'Job Attributes', 'Job Description'])\n",
    "# npo_jobs_df.head()\n",
    "npo_jobs_df.to_csv('npo_jobs.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38064bitvenvvenv31f0f01a22904b30b9afeb6e5122647d",
   "display_name": "Python 3.8.0 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}